{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iv5K1TEe18UV",
    "outputId": "4372ee59-deba-4004-efd2-a311a8fa4897",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://mslearntensorflowlp.blob.core.windows.net/data/oxpets_images.tar.gz\n",
    "!tar xfz oxpets_images.tar.gz\n",
    "!rm oxpets_images.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W4m0I6zT2IC9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from glob import glob\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Rcvj9WK0F5hm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Freeze(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = False\n",
    "        \n",
    "def UnFreeze(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = True\n",
    "\n",
    "def Load(filename) :\n",
    "    img = Image.open(filename)\n",
    "    img = img.convert('RGB')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5sxEWrBHOdu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Загружаем обе модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uy3CJLR4x7K4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import resnet34 as resnet34\n",
    "resnet = resnet34(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.models.vgg import vgg16 as vgg16\n",
    "vgg16 = vgg16(pretrained = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обрабатываем файлы\n",
    "\n",
    "Опишем класс датасета и класс для преобразования датаестов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_list=glob('images/*.jpg')\n",
    "class Pet_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.len = len(data)\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.data[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class Transform_dataset():\n",
    "    \n",
    "    def __init__(self, data, num_cl, val_split=0.2, train_transforms=None, val_transforms=None):\n",
    "        class_values = [[] for x in range(num_cl)]\n",
    "        \n",
    "        for d in data:\n",
    "            class_values[d[1].item()].append(d)\n",
    "            \n",
    "        self.train_data = []\n",
    "        self.val_data = []\n",
    "        \n",
    "        for class_dp in class_values:\n",
    "            split_idx = int(len(class_dp)*(1-val_split))\n",
    "            self.train_data += class_dp[:split_idx]\n",
    "            self.val_data += class_dp[split_idx:]\n",
    "            \n",
    "        self.train_ds = Pet_dataset(self.train_data, transforms=train_transforms)\n",
    "        self.val_ds = Pet_dataset(self.val_data, transforms=val_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes = set()\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for image in img_list:\n",
    "    class_name = image.rsplit('_', 1)[0]\n",
    "    classes.add(class_name)\n",
    "    img = Load(image)\n",
    "\n",
    "    data.append(img)\n",
    "    labels.append(class_name)\n",
    "\n",
    "class2idx = {cl: idx for idx, cl in enumerate(classes)}        \n",
    "labels = torch.Tensor(list(map(lambda x: class2idx[x], labels))).long()\n",
    "\n",
    "data = list(zip(data, labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Опишем алгоритмы преобразования тензоров, полученных из файлов. В обучающей выборке производим аугментацию изображений, схожую с предыдущей частью ЛР"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms =transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    " ])\n",
    "\n",
    "Td = Transform_dataset(data, len(classes), val_split=0.2, train_transforms=train_transforms, val_transforms=val_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz = None):# конкатенация слоев\n",
    "        super(AdaptiveConcatPool2d, self).__init__()\n",
    "        self.output_size = sz or 1\n",
    "        self.ap = nn.AdaptiveAvgPool2d(self.output_size)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(self.output_size)\n",
    "\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "def head_blocks(in_dim, p, out_dim, activation=None):# линейный блок\n",
    "    layers = [\n",
    "        nn.BatchNorm1d(in_dim),\n",
    "        nn.Dropout(p),\n",
    "        nn.Linear(in_dim, out_dim)\n",
    "    ]\n",
    "    \n",
    "    if activation is not None:\n",
    "        layers.append(activation)\n",
    "        \n",
    "    return layers       \n",
    "    \n",
    "def create_head(nf, nc, bn_final=False): # приделываем голову к ResNet\n",
    "    pool = AdaptiveConcatPool2d()\n",
    "    layers = [pool, nn.Flatten()]\n",
    "    layers += head_blocks(nf, 0.25, 512, nn.ReLU(inplace=True))\n",
    "    layers += head_blocks(512, 0.5, nc)\n",
    "    \n",
    "    if bn_final:\n",
    "        layers.append(nn.BatchNorm1d(nc, momentum=0.01))\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "    \n",
    "def requires_grad(layer): \n",
    "    ps = list(layer.parameters())\n",
    "    if not ps: return None\n",
    "    return ps[0].requires_grad\n",
    "\n",
    "def cnn_model(model, nc, bn_final=False, init=nn.init.kaiming_normal_): # Собираем Франкенштейна\n",
    "    \n",
    "    body = nn.Sequential(*list(model.children())[:-2])\n",
    "    head = create_head(1024, nc, bn_final)\n",
    "    \n",
    "    model = nn.Sequential(body, head)\n",
    "    \n",
    "    Freeze(model[0].parameters())\n",
    "    \n",
    "    for child in model[1].children():\n",
    "        if isinstance(child, nn.Module) and (not isinstance(child, bn_types)) and requires_grad(child): \n",
    "            init(child.weight)\n",
    "    \n",
    "    return model\n",
    "\n",
    "num_classes = len(classes)\n",
    "model_resnet34 = cnn_model(resnet, num_classes, bn_final=True)\n",
    "model_vgg16 = cnn_model(vgg16, num_classes, bn_final=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В качестве оптимизаторов будем использовать алгоритм Адам с lr=10e-3, исходя из результата оптимизации параметров предыдущей части ЛР"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_indices = list(range(len(Td.train_ds)))\n",
    "test_indices = list(range(len(Td.val_ds)))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(Td.train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(Td.val_ds, batch_size=64, shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_resnet = optim.Adam(model_resnet34.parameters(), lr=0.001)\n",
    "optimizer_vgg = optim.Adam(model_vgg16.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучаем и смотрим на результаты ResNet34"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "model_resnet34.to(device)\n",
    "\n",
    "def train(epochs, optimizer, model):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_acc = 100. * n_correct / len(Td.train_ds)\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        n_val_correct = 0\n",
    "        val_loss = 0\n",
    "  \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs, labels = batch\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs, labels).item()\n",
    "\n",
    "                n_val_correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "                \n",
    "                \n",
    "                \n",
    "        val_acc = 100. * n_val_correct / len(Td.val_ds)\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "        print('Epoch %s: Train Accuracy: %.2f percent, Validation Accuracy: %.2f percent, Train Loss: %s, Validation Loss: %s' \n",
    "              % (epoch, train_acc, val_acc, train_loss, val_loss))\n",
    "        \n",
    "train(5, optimizer_resnet, model_resnet34)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучаем и смотрим на результаты VGG16"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "model_vgg16.to(device)\n",
    "        \n",
    "train(5, optimizer_vgg, model_vgg16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Несмотря на то, что VGG16 чуть менее точная на обучающей выборке, на валидационной у неё точность выше, а также сильно ниже цена ошибки на ваидационной же выборке, поэтому выбираем её.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def binary_class(val_labels, pred):  # бинарная классификация\n",
    "    v, r = [], []\n",
    "    for i in val_labels:\n",
    "        if i < 12:\n",
    "            v.append(0)\n",
    "        else:\n",
    "            v.append(1)\n",
    "    for i in pred:\n",
    "        if i < 12:\n",
    "            r.append(0)\n",
    "        else:\n",
    "            r.append(1)\n",
    "    return v, r\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict = []  # собираем полную валидационную выборку\n",
    "labels = []\n",
    "for i in test_loader:\n",
    "    input, label = i\n",
    "    input = input.to(device)\n",
    "    label = label.to(device)\n",
    "    y_pred = model_vgg16(input)\n",
    "    _, pred = torch.max(y_pred, 1)\n",
    "    for j in range(len(pred)):\n",
    "        predict.append(pred[j].item())\n",
    "        labels.append(label[j].item())\n",
    "\n",
    "pred, lab = binary_class(labels, predict)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь посмотрим на точность при бинарной классификации"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum_bin = 0\n",
    "for i in range(len(predict)):\n",
    "  if pred[i] == lab[i]:\n",
    "    sum_bin+=1\n",
    "print(\"Binary accuracy:\", sum_bin/len(predict))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Точность 95%, очень хороший показатель"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Посмотрим на ConfusionMatrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(lab, pred)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как мы видим - точность бинарной классификации на высоте. FP и FN одинаково мало, это значит, что сеть хорошо разделяет, как кошек, так и собак. Видим, что собак в датасете больше."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Определим функцию, которая возвращает n наиболее вероятных предсказанных лейблов в порядке убывания"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    pred1 = []\n",
    "    pred2 = []\n",
    "    predict = []\n",
    "    label1 = []\n",
    "    l2 = []\n",
    "    label3 = []\n",
    "    for i in test_loader:\n",
    "        input, label = i\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "        y_pred = model_resnet34(input)\n",
    "        pred1.append(y_pred)\n",
    "        label1.append(label)\n",
    "    for i in pred1:\n",
    "        for j in i:\n",
    "            for k in j:\n",
    "                pred2.append(k.item())\n",
    "            predict.append(pred2)\n",
    "            pred2 = []\n",
    "    predict = np.array(predict)\n",
    "    for i in label1:\n",
    "        for j in i:\n",
    "            label3.append(j.item())\n",
    "    label3 = np.array(label3)\n",
    "    return predict, label3\n",
    "\n",
    "\n",
    "def top_acc(valid, n):  # считает лейбл наиболее вероятного лейбла\n",
    "    res = np.empty((0, n))\n",
    "    for i in valid:\n",
    "        ind = np.flip(i.argsort())[:n]\n",
    "        res = np.append(res, [ind], axis=0)\n",
    "    return res\n",
    "\n",
    "\n",
    "def topn_acc(val_labels, pred):  # считает top-n accuracy\n",
    "    sum_corr = 0\n",
    "    for (i, elem) in enumerate(val_labels):\n",
    "        if elem in pred[i]:\n",
    "            sum_corr += 1\n",
    "    res = sum_corr / val_labels.shape[0]\n",
    "    return res\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict, label3 = get_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Подсчитаем top-3 и top-5 accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y3 =  top_acc(predict,3)\n",
    "y5 = top_acc(predict,5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('top-3 accuracy:', topn_acc(label3,y3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('top-5 accuracy:', topn_acc(label3,y5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как мы видим top-3 accuracy значительно превосходит top-1 accuracy(aka посчитанная точность), а вот уже различия между top-3 accuracy и top-5 accuracy очень мало."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AqjZadAOPScA",
    "outputId": "31d0c0c9-76c2-41ab-cce4-6b1f659f7efd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-3 accuracy: 0.9830966869506423\n"
     ]
    }
   ],
   "source": [
    "print('top-3 accuracy:', topn_acc(label3,y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeniD_4LY6k0",
    "outputId": "6fbb406c-df22-4501-9ec6-ad5903700b6a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 accuracy: 0.9891818796484111\n"
     ]
    }
   ],
   "source": [
    "print('top-5 accuracy:', topn_acc(label3,y5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3hk8ms7ctUH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как мы видим top-3 accuracy значительно превосходит top-1 accuracy(aka посчитанная точность), а вот уже различия между top-3 accuracy и top-5 accuracy очень мало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQpX19tNdBJJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pets-2.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "4fee5f00e471604f138b2a95ee5c96a7fea853470284bcce1030f4018e4910da"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}